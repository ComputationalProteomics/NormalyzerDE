---
title: "Evaluation and statistics of expression data using NormalyzerDE"
author: "Jakob Willforss, Aakash Chawade and Fredrik Levander"
date: "`r format(Sys.Date(), '%m/%d/%Y')`"
abstract: >
    When working with omics data you will encounter technical biases. These can often in part be remedied by using appropriate normalization approach. Normalyzer helps this process by both performing a number of readibly available normalizations as well as generating a summary document of the results.
    NormalyzerDE package version: `r packageVersion("NormalyzerDE")`
output: 
  BiocStyle::pdf_document
vignette: >
  %\VignetteIndexEntry{Differential expression and countering technical biases using NormalyzerDE}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---

```{r setup, echo=FALSE, results="hide"}
# knitr::opts_chunk$set(tidy=FALSE, cache=TRUE, dev="png", message=FALSE,
# error=FALSE, warning=TRUE)
```

# Default use

## Citing

Mention how to cite.

## Input format

NormalyzerDE expects a raw data file. Columns can contain annotation information or sample data.
Each column should start with a header.

```
pepseq  s1      s2      s3      s4
ATAAGG  20.0    21.2    19.4    18.5
AWAG    23.3    24.1    23.5    17.3
ACATGM  22.1    22.3    22.5    23.2
```

This data should be provided with a design matrix where all data samples should be represented.
One column (default header "sample") should match the columns containing samples in the raw data.
Another column (default header "group") should contain condition levels which could be used for group-based
evaluations.

```
sample  group
s1      condA
s2      condA
s3      condB
s4      condB
```

## Running NormalyzerDE evaluation

The evaluation step can be performed with one command, `normalyzer`.
This command expects a path to the data file, a name for the run-job,
a path to a design matrix and finally a path to an output directory.

```{r}
library(NormalyzerDE)
normalyzer(jobName="vignette_run", designPath="design.tsv", dataPath="data.tsv", outputDir="testout")
```

## Running NormalyzerDE statistical comparisons

When you after performing the evaluation and having evaluated the report have decided
for which normalization approach seems to work best you can continue to the statistical step.

Here, expected parameters are the path to the target normalization matrix, the sample design matrix as
in the previous step, a job name, the path to an output directory and a list of the pairwise comparisons
for which you want to calculate contrasts. They are provided as a character vector with conditions to
compare separated by a dash ("-").

```{r}
normalyzerDE("vignette_run", "design.tsv", "testout/vignette_run/Loess-G-normalized.txt", 
             outputDir="testoutstat", comparisons=c("1-2", "1-3", "1-4"))
```

# Retention time normalization

Retention time based normalization can be performed with an arbitrary normalization matrix.

## Basic usage

There are two points of access for the higher order normalization. Either by calling `getRTNormalizedMatrix` which applies the target normalization approach stepwise over the matrix based on retention times, or by calling `getSmoothedRTNormalizedMatrix` which generates multiple layered matrices and combines them. To use them you need your raw data loaded into a matrix, a list containing retention times and a normalization matrix able to take a raw matrix and return a normalized in similar format.

```{r}
fullDf <- read.csv("data.tsv", sep="\t")
designDf <- read.csv("design.tsv", sep="\t")
head(fullDf, 1)
head(designDf, 1)
```

At this point we have loaded the full data into dataframes. Next, we use the sample names present in the design matrix to extract sample columns from the raw data. Be careful that the sample names is a character vector. If it is a factor it will extract wrong columns.

Make sure that sample names extracted from design matrix are in right format. We expect it to be in 'character' format.

```{r}
sampleNames <- as.character(designDf$sample)
typeof(sampleNames)
```

Now we are ready to extract the data matrix from the full matrix. We also need to get the retention time column from the full matrix.

```{r}
dataMat <- as.matrix(fullDf[, sampleNames])
retentionTimes <- fullDf$Average.RT

head(dataMat, 1)
```

If everything is fine the data matrix should be `double`, and have the same number of rows as the number of retention time values we have.

```{r}
typeof(dataMat)

print("Rows and columns of data")
dim(dataMat)

print("Number of retention times")
length(retentionTimes)
```

The normalization function is expected to take a raw intensity matrix (?) and return log transformed values. We borrow the function for Loess normalization from NormalyzerDE. As long as it follow the same input/output format it could be replaced with a custom function.

```{r}
performCyclicLoessNormalization <- function(rawMatrix) {
    log2Matrix <- log2(rawMatrix)
    normMatrix <- limma::normalizeCyclicLoess(log2Matrix, method="fast")
    colnames(normMatrix) <- colnames(rawMatrix)
    normMatrix
}
```

We are ready to perform the normalization.

```{r}
rtNormMat <- getRTNormalizedMatrix(dataMat, retentionTimes, performCyclicLoessNormalization, stepSizeMinutes=1, windowMinCount=100)
```

Let's double check the results. We expect a matrix in the same format and shape as before. Furthermore, we expect similar but not the exact same values as if we'd applied the normalization globally.

```{r}
globalNormMat <- performCyclicLoessNormalization(dataMat)
dim(rtNormMat)
dim(globalNormMat)
head(rtNormMat, 1)
head(globalNormMat, 1)
```

## Performing layered normalization

We have everything set up to perform the layered normalization. The result here is expected to be overall similar to the normal retention time approach.

```{r}
layeredRtNormMat <- getSmoothedRTNormalizedMatrix(dataMat, retentionTimes, performCyclicLoessNormalization, stepSizeMinutes=1, windowMinCount=100, frameShifts=3, mergeMethod="mean")

dim(layeredRtNormMat)
head(layeredRtNormMat, 1)
```

## Defining a wrapper

# Stepwise processing

NormalyzerDE consists of a set of steps. You can influence the order of this processing using options (X and X), but they can also be called directly from R.

## Step 1: Loading data

This step performs input validation of the data, and generates an object of the class NormalyzerDataset.

```{r}
jobName <- "vignette_run"
normObj <- getVerifiedNormalyzerObject(jobName, "design.tsv", "data.tsv")
```

## Step 2: Generate normalizations

Here, normalizations are performed. This generates a NormalyzerResults object containing both a reference to its original dataset object, but also generated normalization matrices.

```{r}
normResults <- normMethods(normObj)
```

## Step 3: Generate performance measures

Performance measures are calculated for normalizations. These are stored in an object NormalizationEvaluationResults. A NormalyzerResults object similar to the one sent in is returned, but with this field added.

```{r}
normResultsWithEval <- analyzeNormalizations(normResults)
```

## Step 4: Output matrices to file

Generated normalization matrices are written to the provided folder.

```{r}
jobDir <- setupJobDir("vignette_run", ".")
writeNormalizedDatasets(normResultsWithEval, jobDir)
```

## Step 5: Generate evaluation plots

Performance measures are used to generate evaluation figures which is written in an evaluation report.

```{r}
generatePlots(normResultsWithEval, jobDir)
```

After this evaluation of normalizations and progression to statistics follows as described previously in this report.















